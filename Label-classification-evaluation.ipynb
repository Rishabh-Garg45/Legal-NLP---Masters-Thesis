{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13372467,"sourceType":"datasetVersion","datasetId":8483803}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install -U transformers accelerate bitsandbytes torch  # install/upgrade first\nimport os\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers.utils import logging\n\nlogging.set_verbosity_error()  # quieter\n\nHF_TOKEN = \"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\"  # prefer env var\nMODEL_ID = \"khalidrajan/Llama-3.1-8B-Instruct-Legal-NLI\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN, use_fast=True)\n\ndef load_model():\n    # Try low-memory safe load first\n    try:\n        model = AutoModelForCausalLM.from_pretrained(\n            MODEL_ID,\n            token=HF_TOKEN,\n            device_map=\"auto\",                # let accelerate dispatch\n            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n            low_cpu_mem_usage=True,           # key flag to avoid partial offload/meta devices\n            offload_folder=\"/tmp/model_offload\",  # optional: where to offload\n            offload_state_dict=True,          # helpful for very large models\n            use_safetensors=True,             # safer & faster if available\n        )\n        return model\n    except Exception as e:\n        print(\"Primary load failed:\", repr(e))\n\n    # Fallback: try loading in 4-bit (requires bitsandbytes)\n    try:\n        print(\"Attempting 4-bit (bitsandbytes) load as fallback...\")\n        model = AutoModelForCausalLM.from_pretrained(\n            MODEL_ID,\n            token=HF_TOKEN,\n            device_map=\"auto\",\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n            low_cpu_mem_usage=True,\n        )\n        return model\n    except Exception as e2:\n        print(\"4-bit fallback also failed:\", repr(e2))\n\n    # Last-resort: load to CPU only (may be slow and may OOM)\n    try:\n        print(\"Final fallback: loading onto CPU (may be very slow).\")\n        model = AutoModelForCausalLM.from_pretrained(\n            MODEL_ID,\n            token=HF_TOKEN,\n            torch_dtype=torch.float32,\n            device_map={\"\": \"cpu\"},\n            low_cpu_mem_usage=True,\n        )\n        return model\n    except Exception as e3:\n        print(\"CPU fallback failed:\", repr(e3))\n        raise RuntimeError(\"All model load attempts failed. See traces above.\")\n\n# Usage\nif __name__ == \"__main__\":\n    # upgrade accelerate & transformers if you run into weird device_map behaviour:\n    # pip install -U accelerate transformers\n    model = load_model()\n    print(\"Model loaded on devices:\", {k: v.device for k, v in model.named_parameters() if hasattr(v, \"device\")}.keys())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-05T06:13:48.633836Z","iopub.execute_input":"2026-01-05T06:13:48.634024Z","iopub.status.idle":"2026-01-05T06:45:06.041108Z","shell.execute_reply.started":"2026-01-05T06:13:48.634008Z","shell.execute_reply":"2026-01-05T06:45:06.040166Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nBase model: Equall/Saul-7B-Instruct-v1\nJudge model: mistralai/Mistral-7B-Instruct-v0.2\nTotal pairs: 40506\nUnique sentences to classify: 1000\nLoading base model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73c57d1c8af6443781af6661527ee621"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86898b78cc7c40ea97e9e589c94bebfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"885bf171c20e48daa4c82333edc43d3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c91dc6221f24c18b3711335d2e435eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12dc081143f04a8c80deee9b4f7fb9ce"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2026-01-05 06:14:11.478490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767593651.653041      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767593651.700938      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ae215bef498404c881858123562834a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb1b7baa0a074a2e8d52f29816faedac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00006.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3923ddcf625845dda480d0dae4dd4546"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00006.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae912b48f69481e8c4d621bf5ec717f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00006.safetensors:   0%|          | 0.00/4.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e01e457214442e8969821f3cf2726e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00006.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63a75e7e59fa42d5b6373153612e3d4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00006.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2499e9625ec44bcaa1869fbf1b0cff12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00006.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3b3422d247542f887940c1c2a687f3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9bd9ed58ed04414b3217692dab000e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bfb0454b127451f8c7b171ddc244f5d"}},"metadata":{}},{"name":"stdout","text":"Running base model in batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c8a31827b304b85b4b79bee925cf6dd"}},"metadata":{}},{"name":"stdout","text":"Base pass done. Distribution: Counter({'non-argumentative': 585, 'premise': 301, 'conclusion': 114})\nFreed base model from GPU.\nLoading judge model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7ec530c944943619d0cbc1cb0be3906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66f6757a61f84a31b4f254821272946c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e68aea77ac07458ba94512065965bcbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff696cd650547acb0c2f15713a8cbe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f81b576639f645f0856c4a82139daade"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c52e20324774f8ba697e03077599736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d20651a4f5d43c58894cdf584a674d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1731b492a0b84469adc0abb6ff0198b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b64a2afa7d24a1287fb4e496aab8e95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e3b986e63384b0995bb461cf326fd68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07580f3983fb41e6bc0b2006c359570b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"067cbf186ed041658cc3c268eebcf7db"}},"metadata":{}},{"name":"stdout","text":"Running judge model in batches...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"698a6856a84343f896881f53b1ea9374"}},"metadata":{}},{"name":"stdout","text":"Intermediate saved up to 4/1000\nIntermediate saved up to 204/1000\nIntermediate saved up to 404/1000\nIntermediate saved up to 604/1000\nIntermediate saved up to 804/1000\nJudge pass done.\nFreed judge model from GPU.\nFinal distributions (base): Counter({'non-argumentative': 585, 'premise': 301, 'conclusion': 114})\nFinal distributions (final): Counter({'premise': 714, 'conclusion': 189, 'non-argumentative': 97})\nSaved: /kaggle/working/sentence_argument_labels_with_big_judge.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom collections import Counter\nimport numpy as np\n\n# Load results (already in memory if run in same notebook)\ndf = df_sentences.copy()\n\nbase = df[\"base_llm_label\"].astype(str)\nfinal = df[\"final_llm_label\"].astype(str)\n\nassert len(base) == len(final), \"Label length mismatch\"\n\nN = len(df)\n\n# -------------------------\n# 1. Overall Change Metrics\n# -------------------------\nchanged_mask = base != final\nnum_changed = changed_mask.sum()\n\nchange_rate = num_changed / N\nstability_rate = 1.0 - change_rate\n\nprint(\"===== Overall Judge Impact =====\")\nprint(f\"Total sentences          : {N}\")\nprint(f\"Labels changed by judge  : {num_changed}\")\nprint(f\"Change rate              : {change_rate:.4f} ({change_rate*100:.2f}%)\")\nprint(f\"Stability (agreement)    : {stability_rate:.4f} ({stability_rate*100:.2f}%)\")\n\n# -------------------------\n# 2. Flip Confusion Matrix\n# -------------------------\nlabels = sorted(set(base) | set(final))\nflip_matrix = pd.crosstab(base, final, rownames=[\"Base\"], colnames=[\"Judge\"])\n\nprint(\"\\n===== Label Flip Matrix (Base → Judge) =====\")\ndisplay(flip_matrix)\n\n# -------------------------\n# 3. Normalized Flip Matrix\n# -------------------------\nflip_norm = flip_matrix.div(flip_matrix.sum(axis=1), axis=0).fillna(0)\n\nprint(\"\\n===== Normalized Flip Matrix (Row-wise %) =====\")\ndisplay((flip_norm * 100).round(2))\n\n# -------------------------\n# 4. Per-Class Change Rates\n# -------------------------\nprint(\"\\n===== Per-Class Change Rate =====\")\nfor lbl in labels:\n    mask = base == lbl\n    if mask.sum() == 0:\n        continue\n    changed = (final[mask] != lbl).sum()\n    rate = changed / mask.sum()\n    print(f\"{lbl:18s}: {changed:5d}/{mask.sum():5d}  ({rate*100:6.2f}%)\")\n\n# -------------------------\n# 5. Net Gain / Loss per Class\n# -------------------------\nbase_counts = Counter(base)\nfinal_counts = Counter(final)\n\nprint(\"\\n===== Net Label Redistribution =====\")\nfor lbl in labels:\n    delta = final_counts[lbl] - base_counts[lbl]\n    sign = \"+\" if delta >= 0 else \"\"\n    print(f\"{lbl:18s}: {base_counts[lbl]:6d} → {final_counts[lbl]:6d}  ({sign}{delta})\")\n\n# -------------------------\n# 6. Judge Correction Focus\n# -------------------------\ncorrections = df.loc[changed_mask, [\"base_llm_label\", \"final_llm_label\"]]\ntop_corrections = (\n    corrections\n    .value_counts()\n    .rename(\"count\")\n    .reset_index()\n)\n\nprint(\"\\n===== Most Common Corrections (Top 10) =====\")\ndisplay(top_corrections.head(10))\n\n# -------------------------\n# 7. Paper-Ready Summary Numbers\n# -------------------------\nsummary = {\n    \"total_sentences\": N,\n    \"changed_labels\": num_changed,\n    \"change_rate_pct\": round(change_rate * 100, 2),\n    \"agreement_pct\": round(stability_rate * 100, 2),\n}\n\nsummary_df = pd.DataFrame([summary])\nprint(\"\\n===== Paper-Ready Summary =====\")\ndisplay(summary_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T06:45:06.044210Z","iopub.execute_input":"2026-01-05T06:45:06.044441Z","iopub.status.idle":"2026-01-05T06:45:06.116446Z","shell.execute_reply.started":"2026-01-05T06:45:06.044424Z","shell.execute_reply":"2026-01-05T06:45:06.115863Z"}},"outputs":[{"name":"stdout","text":"===== Overall Judge Impact =====\nTotal sentences          : 1000\nLabels changed by judge  : 610\nChange rate              : 0.6100 (61.00%)\nStability (agreement)    : 0.3900 (39.00%)\n\n===== Label Flip Matrix (Base → Judge) =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Judge              conclusion  non-argumentative  premise\nBase                                                     \nconclusion                 72                  2       40\nnon-argumentative          49                 90      446\npremise                    68                  5      228","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Judge</th>\n      <th>conclusion</th>\n      <th>non-argumentative</th>\n      <th>premise</th>\n    </tr>\n    <tr>\n      <th>Base</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>conclusion</th>\n      <td>72</td>\n      <td>2</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>non-argumentative</th>\n      <td>49</td>\n      <td>90</td>\n      <td>446</td>\n    </tr>\n    <tr>\n      <th>premise</th>\n      <td>68</td>\n      <td>5</td>\n      <td>228</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n===== Normalized Flip Matrix (Row-wise %) =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Judge              conclusion  non-argumentative  premise\nBase                                                     \nconclusion              63.16               1.75    35.09\nnon-argumentative        8.38              15.38    76.24\npremise                 22.59               1.66    75.75","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Judge</th>\n      <th>conclusion</th>\n      <th>non-argumentative</th>\n      <th>premise</th>\n    </tr>\n    <tr>\n      <th>Base</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>conclusion</th>\n      <td>63.16</td>\n      <td>1.75</td>\n      <td>35.09</td>\n    </tr>\n    <tr>\n      <th>non-argumentative</th>\n      <td>8.38</td>\n      <td>15.38</td>\n      <td>76.24</td>\n    </tr>\n    <tr>\n      <th>premise</th>\n      <td>22.59</td>\n      <td>1.66</td>\n      <td>75.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n===== Per-Class Change Rate =====\nconclusion        :    42/  114  ( 36.84%)\nnon-argumentative :   495/  585  ( 84.62%)\npremise           :    73/  301  ( 24.25%)\n\n===== Net Label Redistribution =====\nconclusion        :    114 →    189  (+75)\nnon-argumentative :    585 →     97  (-488)\npremise           :    301 →    714  (+413)\n\n===== Most Common Corrections (Top 10) =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      base_llm_label    final_llm_label  count\n0  non-argumentative            premise    446\n1            premise         conclusion     68\n2  non-argumentative         conclusion     49\n3         conclusion            premise     40\n4            premise  non-argumentative      5\n5         conclusion  non-argumentative      2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>base_llm_label</th>\n      <th>final_llm_label</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>non-argumentative</td>\n      <td>premise</td>\n      <td>446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>premise</td>\n      <td>conclusion</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>non-argumentative</td>\n      <td>conclusion</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>conclusion</td>\n      <td>premise</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>premise</td>\n      <td>non-argumentative</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>conclusion</td>\n      <td>non-argumentative</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n===== Paper-Ready Summary =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   total_sentences  changed_labels  change_rate_pct  agreement_pct\n0             1000             610             61.0           39.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_sentences</th>\n      <th>changed_labels</th>\n      <th>change_rate_pct</th>\n      <th>agreement_pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>610</td>\n      <td>61.0</td>\n      <td>39.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}